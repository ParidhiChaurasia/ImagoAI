{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"TASK-ML-INTERN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsi_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>vomitoxin_ppb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagoai_corn_0</td>\n",
       "      <td>0.416181</td>\n",
       "      <td>0.396844</td>\n",
       "      <td>0.408985</td>\n",
       "      <td>0.372865</td>\n",
       "      <td>0.385293</td>\n",
       "      <td>0.365390</td>\n",
       "      <td>0.355226</td>\n",
       "      <td>0.343350</td>\n",
       "      <td>0.344837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.717482</td>\n",
       "      <td>0.715078</td>\n",
       "      <td>0.705379</td>\n",
       "      <td>0.696691</td>\n",
       "      <td>0.692793</td>\n",
       "      <td>0.711369</td>\n",
       "      <td>0.697679</td>\n",
       "      <td>0.704520</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagoai_corn_1</td>\n",
       "      <td>0.415797</td>\n",
       "      <td>0.402956</td>\n",
       "      <td>0.402564</td>\n",
       "      <td>0.396014</td>\n",
       "      <td>0.397192</td>\n",
       "      <td>0.389634</td>\n",
       "      <td>0.375671</td>\n",
       "      <td>0.363689</td>\n",
       "      <td>0.373883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684011</td>\n",
       "      <td>0.697271</td>\n",
       "      <td>0.701995</td>\n",
       "      <td>0.696077</td>\n",
       "      <td>0.701012</td>\n",
       "      <td>0.677418</td>\n",
       "      <td>0.696921</td>\n",
       "      <td>0.696544</td>\n",
       "      <td>0.689054</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagoai_corn_2</td>\n",
       "      <td>0.389023</td>\n",
       "      <td>0.371206</td>\n",
       "      <td>0.373098</td>\n",
       "      <td>0.373872</td>\n",
       "      <td>0.361056</td>\n",
       "      <td>0.349709</td>\n",
       "      <td>0.333882</td>\n",
       "      <td>0.330841</td>\n",
       "      <td>0.328925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683054</td>\n",
       "      <td>0.669286</td>\n",
       "      <td>0.663179</td>\n",
       "      <td>0.676165</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>0.655951</td>\n",
       "      <td>0.658945</td>\n",
       "      <td>0.670989</td>\n",
       "      <td>0.665176</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imagoai_corn_3</td>\n",
       "      <td>0.468837</td>\n",
       "      <td>0.473255</td>\n",
       "      <td>0.462949</td>\n",
       "      <td>0.459335</td>\n",
       "      <td>0.461672</td>\n",
       "      <td>0.459824</td>\n",
       "      <td>0.458194</td>\n",
       "      <td>0.427737</td>\n",
       "      <td>0.415360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.730801</td>\n",
       "      <td>0.736787</td>\n",
       "      <td>0.730044</td>\n",
       "      <td>0.751437</td>\n",
       "      <td>0.738497</td>\n",
       "      <td>0.742446</td>\n",
       "      <td>0.754657</td>\n",
       "      <td>0.733474</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imagoai_corn_4</td>\n",
       "      <td>0.483352</td>\n",
       "      <td>0.487274</td>\n",
       "      <td>0.469153</td>\n",
       "      <td>0.487648</td>\n",
       "      <td>0.464026</td>\n",
       "      <td>0.451152</td>\n",
       "      <td>0.458229</td>\n",
       "      <td>0.440782</td>\n",
       "      <td>0.426193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770227</td>\n",
       "      <td>0.773013</td>\n",
       "      <td>0.761431</td>\n",
       "      <td>0.763488</td>\n",
       "      <td>0.762473</td>\n",
       "      <td>0.744012</td>\n",
       "      <td>0.775486</td>\n",
       "      <td>0.760431</td>\n",
       "      <td>0.751988</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hsi_id         0         1         2         3         4         5  \\\n",
       "0  imagoai_corn_0  0.416181  0.396844  0.408985  0.372865  0.385293  0.365390   \n",
       "1  imagoai_corn_1  0.415797  0.402956  0.402564  0.396014  0.397192  0.389634   \n",
       "2  imagoai_corn_2  0.389023  0.371206  0.373098  0.373872  0.361056  0.349709   \n",
       "3  imagoai_corn_3  0.468837  0.473255  0.462949  0.459335  0.461672  0.459824   \n",
       "4  imagoai_corn_4  0.483352  0.487274  0.469153  0.487648  0.464026  0.451152   \n",
       "\n",
       "          6         7         8  ...       439       440       441       442  \\\n",
       "0  0.355226  0.343350  0.344837  ...  0.710280  0.717482  0.715078  0.705379   \n",
       "1  0.375671  0.363689  0.373883  ...  0.684011  0.697271  0.701995  0.696077   \n",
       "2  0.333882  0.330841  0.328925  ...  0.683054  0.669286  0.663179  0.676165   \n",
       "3  0.458194  0.427737  0.415360  ...  0.742782  0.730801  0.736787  0.730044   \n",
       "4  0.458229  0.440782  0.426193  ...  0.770227  0.773013  0.761431  0.763488   \n",
       "\n",
       "        443       444       445       446       447  vomitoxin_ppb  \n",
       "0  0.696691  0.692793  0.711369  0.697679  0.704520         1100.0  \n",
       "1  0.701012  0.677418  0.696921  0.696544  0.689054         1000.0  \n",
       "2  0.676591  0.655951  0.658945  0.670989  0.665176         1300.0  \n",
       "3  0.751437  0.738497  0.742446  0.754657  0.733474         1300.0  \n",
       "4  0.762473  0.744012  0.775486  0.760431  0.751988          220.0  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 450)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>vomitoxin_ppb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.443118</td>\n",
       "      <td>0.440761</td>\n",
       "      <td>0.433814</td>\n",
       "      <td>0.426122</td>\n",
       "      <td>0.418990</td>\n",
       "      <td>0.412432</td>\n",
       "      <td>0.405868</td>\n",
       "      <td>0.399815</td>\n",
       "      <td>0.394038</td>\n",
       "      <td>0.389664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741255</td>\n",
       "      <td>0.740818</td>\n",
       "      <td>0.740459</td>\n",
       "      <td>0.739758</td>\n",
       "      <td>0.739850</td>\n",
       "      <td>0.738738</td>\n",
       "      <td>0.738298</td>\n",
       "      <td>0.737599</td>\n",
       "      <td>0.738099</td>\n",
       "      <td>3410.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.044719</td>\n",
       "      <td>0.045520</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>0.046070</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>0.044727</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>0.043773</td>\n",
       "      <td>0.043659</td>\n",
       "      <td>0.043442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053479</td>\n",
       "      <td>0.053695</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.053666</td>\n",
       "      <td>0.053487</td>\n",
       "      <td>0.053601</td>\n",
       "      <td>0.054014</td>\n",
       "      <td>0.054136</td>\n",
       "      <td>0.054297</td>\n",
       "      <td>13095.803483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.311182</td>\n",
       "      <td>0.295321</td>\n",
       "      <td>0.284064</td>\n",
       "      <td>0.282054</td>\n",
       "      <td>0.296702</td>\n",
       "      <td>0.286860</td>\n",
       "      <td>0.262876</td>\n",
       "      <td>0.278523</td>\n",
       "      <td>0.255529</td>\n",
       "      <td>0.261459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562662</td>\n",
       "      <td>0.585011</td>\n",
       "      <td>0.558412</td>\n",
       "      <td>0.571735</td>\n",
       "      <td>0.575259</td>\n",
       "      <td>0.571767</td>\n",
       "      <td>0.577803</td>\n",
       "      <td>0.576985</td>\n",
       "      <td>0.562302</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.410456</td>\n",
       "      <td>0.404310</td>\n",
       "      <td>0.397038</td>\n",
       "      <td>0.389029</td>\n",
       "      <td>0.382102</td>\n",
       "      <td>0.377157</td>\n",
       "      <td>0.369620</td>\n",
       "      <td>0.364823</td>\n",
       "      <td>0.360634</td>\n",
       "      <td>0.355246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702105</td>\n",
       "      <td>0.703701</td>\n",
       "      <td>0.702988</td>\n",
       "      <td>0.700889</td>\n",
       "      <td>0.701690</td>\n",
       "      <td>0.700638</td>\n",
       "      <td>0.698655</td>\n",
       "      <td>0.698107</td>\n",
       "      <td>0.699673</td>\n",
       "      <td>137.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.449105</td>\n",
       "      <td>0.442651</td>\n",
       "      <td>0.434215</td>\n",
       "      <td>0.425074</td>\n",
       "      <td>0.417075</td>\n",
       "      <td>0.411872</td>\n",
       "      <td>0.405443</td>\n",
       "      <td>0.397917</td>\n",
       "      <td>0.393803</td>\n",
       "      <td>0.387211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743857</td>\n",
       "      <td>0.745922</td>\n",
       "      <td>0.745062</td>\n",
       "      <td>0.743991</td>\n",
       "      <td>0.744004</td>\n",
       "      <td>0.743965</td>\n",
       "      <td>0.743301</td>\n",
       "      <td>0.745216</td>\n",
       "      <td>0.745733</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.480245</td>\n",
       "      <td>0.478822</td>\n",
       "      <td>0.473158</td>\n",
       "      <td>0.464947</td>\n",
       "      <td>0.459232</td>\n",
       "      <td>0.452198</td>\n",
       "      <td>0.444384</td>\n",
       "      <td>0.438728</td>\n",
       "      <td>0.431165</td>\n",
       "      <td>0.427039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777884</td>\n",
       "      <td>0.776210</td>\n",
       "      <td>0.777069</td>\n",
       "      <td>0.774759</td>\n",
       "      <td>0.775698</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>0.775621</td>\n",
       "      <td>0.774635</td>\n",
       "      <td>0.774310</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.556287</td>\n",
       "      <td>0.530168</td>\n",
       "      <td>0.528774</td>\n",
       "      <td>0.533202</td>\n",
       "      <td>0.511909</td>\n",
       "      <td>0.501786</td>\n",
       "      <td>0.504054</td>\n",
       "      <td>0.490692</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.472080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940642</td>\n",
       "      <td>0.940361</td>\n",
       "      <td>0.939153</td>\n",
       "      <td>0.930366</td>\n",
       "      <td>0.942615</td>\n",
       "      <td>0.945225</td>\n",
       "      <td>0.932812</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.957860</td>\n",
       "      <td>131000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     0.443118    0.440761    0.433814    0.426122    0.418990    0.412432   \n",
       "std      0.044719    0.045520    0.045764    0.046070    0.045405    0.044727   \n",
       "min      0.311182    0.295321    0.284064    0.282054    0.296702    0.286860   \n",
       "25%      0.410456    0.404310    0.397038    0.389029    0.382102    0.377157   \n",
       "50%      0.449105    0.442651    0.434215    0.425074    0.417075    0.411872   \n",
       "75%      0.480245    0.478822    0.473158    0.464947    0.459232    0.452198   \n",
       "max      0.556287    0.530168    0.528774    0.533202    0.511909    0.501786   \n",
       "\n",
       "                6           7           8           9  ...         439  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  ...  500.000000   \n",
       "mean     0.405868    0.399815    0.394038    0.389664  ...    0.741255   \n",
       "std      0.044528    0.043773    0.043659    0.043442  ...    0.053479   \n",
       "min      0.262876    0.278523    0.255529    0.261459  ...    0.562662   \n",
       "25%      0.369620    0.364823    0.360634    0.355246  ...    0.702105   \n",
       "50%      0.405443    0.397917    0.393803    0.387211  ...    0.743857   \n",
       "75%      0.444384    0.438728    0.431165    0.427039  ...    0.777884   \n",
       "max      0.504054    0.490692    0.489272    0.472080  ...    0.940642   \n",
       "\n",
       "              440         441         442         443         444         445  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     0.740818    0.740459    0.739758    0.739850    0.738738    0.738298   \n",
       "std      0.053695    0.053812    0.053666    0.053487    0.053601    0.054014   \n",
       "min      0.585011    0.558412    0.571735    0.575259    0.571767    0.577803   \n",
       "25%      0.703701    0.702988    0.700889    0.701690    0.700638    0.698655   \n",
       "50%      0.745922    0.745062    0.743991    0.744004    0.743965    0.743301   \n",
       "75%      0.776210    0.777069    0.774759    0.775698    0.775686    0.775621   \n",
       "max      0.940361    0.939153    0.930366    0.942615    0.945225    0.932812   \n",
       "\n",
       "              446         447  vomitoxin_ppb  \n",
       "count  500.000000  500.000000     500.000000  \n",
       "mean     0.737599    0.738099    3410.006000  \n",
       "std      0.054136    0.054297   13095.803483  \n",
       "min      0.576985    0.562302       0.000000  \n",
       "25%      0.698107    0.699673     137.500000  \n",
       "50%      0.745216    0.745733     500.000000  \n",
       "75%      0.774635    0.774310    1700.000000  \n",
       "max      0.931381    0.957860  131000.000000  \n",
       "\n",
       "[8 rows x 449 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Columns: 450 entries, hsi_id to vomitoxin_ppb\n",
      "dtypes: float64(449), object(1)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hsi_id           0\n",
       "0                0\n",
       "1                0\n",
       "2                0\n",
       "3                0\n",
       "                ..\n",
       "444              0\n",
       "445              0\n",
       "446              0\n",
       "447              0\n",
       "vomitoxin_ppb    0\n",
       "Length: 450, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hsi_id\"] = df[\"hsi_id\"].str.extract(\"(\\d+)\").astype(float).astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsi_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>vomitoxin_ppb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.416181</td>\n",
       "      <td>0.396844</td>\n",
       "      <td>0.408985</td>\n",
       "      <td>0.372865</td>\n",
       "      <td>0.385293</td>\n",
       "      <td>0.365390</td>\n",
       "      <td>0.355226</td>\n",
       "      <td>0.343350</td>\n",
       "      <td>0.344837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.717482</td>\n",
       "      <td>0.715078</td>\n",
       "      <td>0.705379</td>\n",
       "      <td>0.696691</td>\n",
       "      <td>0.692793</td>\n",
       "      <td>0.711369</td>\n",
       "      <td>0.697679</td>\n",
       "      <td>0.704520</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.415797</td>\n",
       "      <td>0.402956</td>\n",
       "      <td>0.402564</td>\n",
       "      <td>0.396014</td>\n",
       "      <td>0.397192</td>\n",
       "      <td>0.389634</td>\n",
       "      <td>0.375671</td>\n",
       "      <td>0.363689</td>\n",
       "      <td>0.373883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684011</td>\n",
       "      <td>0.697271</td>\n",
       "      <td>0.701995</td>\n",
       "      <td>0.696077</td>\n",
       "      <td>0.701012</td>\n",
       "      <td>0.677418</td>\n",
       "      <td>0.696921</td>\n",
       "      <td>0.696544</td>\n",
       "      <td>0.689054</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.389023</td>\n",
       "      <td>0.371206</td>\n",
       "      <td>0.373098</td>\n",
       "      <td>0.373872</td>\n",
       "      <td>0.361056</td>\n",
       "      <td>0.349709</td>\n",
       "      <td>0.333882</td>\n",
       "      <td>0.330841</td>\n",
       "      <td>0.328925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683054</td>\n",
       "      <td>0.669286</td>\n",
       "      <td>0.663179</td>\n",
       "      <td>0.676165</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>0.655951</td>\n",
       "      <td>0.658945</td>\n",
       "      <td>0.670989</td>\n",
       "      <td>0.665176</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.468837</td>\n",
       "      <td>0.473255</td>\n",
       "      <td>0.462949</td>\n",
       "      <td>0.459335</td>\n",
       "      <td>0.461672</td>\n",
       "      <td>0.459824</td>\n",
       "      <td>0.458194</td>\n",
       "      <td>0.427737</td>\n",
       "      <td>0.415360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.730801</td>\n",
       "      <td>0.736787</td>\n",
       "      <td>0.730044</td>\n",
       "      <td>0.751437</td>\n",
       "      <td>0.738497</td>\n",
       "      <td>0.742446</td>\n",
       "      <td>0.754657</td>\n",
       "      <td>0.733474</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.483352</td>\n",
       "      <td>0.487274</td>\n",
       "      <td>0.469153</td>\n",
       "      <td>0.487648</td>\n",
       "      <td>0.464026</td>\n",
       "      <td>0.451152</td>\n",
       "      <td>0.458229</td>\n",
       "      <td>0.440782</td>\n",
       "      <td>0.426193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770227</td>\n",
       "      <td>0.773013</td>\n",
       "      <td>0.761431</td>\n",
       "      <td>0.763488</td>\n",
       "      <td>0.762473</td>\n",
       "      <td>0.744012</td>\n",
       "      <td>0.775486</td>\n",
       "      <td>0.760431</td>\n",
       "      <td>0.751988</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hsi_id         0         1         2         3         4         5  \\\n",
       "0       0  0.416181  0.396844  0.408985  0.372865  0.385293  0.365390   \n",
       "1       1  0.415797  0.402956  0.402564  0.396014  0.397192  0.389634   \n",
       "2       2  0.389023  0.371206  0.373098  0.373872  0.361056  0.349709   \n",
       "3       3  0.468837  0.473255  0.462949  0.459335  0.461672  0.459824   \n",
       "4       4  0.483352  0.487274  0.469153  0.487648  0.464026  0.451152   \n",
       "\n",
       "          6         7         8  ...       439       440       441       442  \\\n",
       "0  0.355226  0.343350  0.344837  ...  0.710280  0.717482  0.715078  0.705379   \n",
       "1  0.375671  0.363689  0.373883  ...  0.684011  0.697271  0.701995  0.696077   \n",
       "2  0.333882  0.330841  0.328925  ...  0.683054  0.669286  0.663179  0.676165   \n",
       "3  0.458194  0.427737  0.415360  ...  0.742782  0.730801  0.736787  0.730044   \n",
       "4  0.458229  0.440782  0.426193  ...  0.770227  0.773013  0.761431  0.763488   \n",
       "\n",
       "        443       444       445       446       447  vomitoxin_ppb  \n",
       "0  0.696691  0.692793  0.711369  0.697679  0.704520         1100.0  \n",
       "1  0.701012  0.677418  0.696921  0.696544  0.689054         1000.0  \n",
       "2  0.676591  0.655951  0.658945  0.670989  0.665176         1300.0  \n",
       "3  0.751437  0.738497  0.742446  0.754657  0.733474         1300.0  \n",
       "4  0.762473  0.744012  0.775486  0.760431  0.751988          220.0  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.iloc[:, :-1].values  # All columns except last\n",
    "y = df.iloc[:, -1].values   # Last column (target variable)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsi_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>vomitoxin_ppb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.416181</td>\n",
       "      <td>0.396844</td>\n",
       "      <td>0.408985</td>\n",
       "      <td>0.372865</td>\n",
       "      <td>0.385293</td>\n",
       "      <td>0.365390</td>\n",
       "      <td>0.355226</td>\n",
       "      <td>0.343350</td>\n",
       "      <td>0.344837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.717482</td>\n",
       "      <td>0.715078</td>\n",
       "      <td>0.705379</td>\n",
       "      <td>0.696691</td>\n",
       "      <td>0.692793</td>\n",
       "      <td>0.711369</td>\n",
       "      <td>0.697679</td>\n",
       "      <td>0.704520</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.415797</td>\n",
       "      <td>0.402956</td>\n",
       "      <td>0.402564</td>\n",
       "      <td>0.396014</td>\n",
       "      <td>0.397192</td>\n",
       "      <td>0.389634</td>\n",
       "      <td>0.375671</td>\n",
       "      <td>0.363689</td>\n",
       "      <td>0.373883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684011</td>\n",
       "      <td>0.697271</td>\n",
       "      <td>0.701995</td>\n",
       "      <td>0.696077</td>\n",
       "      <td>0.701012</td>\n",
       "      <td>0.677418</td>\n",
       "      <td>0.696921</td>\n",
       "      <td>0.696544</td>\n",
       "      <td>0.689054</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.389023</td>\n",
       "      <td>0.371206</td>\n",
       "      <td>0.373098</td>\n",
       "      <td>0.373872</td>\n",
       "      <td>0.361056</td>\n",
       "      <td>0.349709</td>\n",
       "      <td>0.333882</td>\n",
       "      <td>0.330841</td>\n",
       "      <td>0.328925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683054</td>\n",
       "      <td>0.669286</td>\n",
       "      <td>0.663179</td>\n",
       "      <td>0.676165</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>0.655951</td>\n",
       "      <td>0.658945</td>\n",
       "      <td>0.670989</td>\n",
       "      <td>0.665176</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.468837</td>\n",
       "      <td>0.473255</td>\n",
       "      <td>0.462949</td>\n",
       "      <td>0.459335</td>\n",
       "      <td>0.461672</td>\n",
       "      <td>0.459824</td>\n",
       "      <td>0.458194</td>\n",
       "      <td>0.427737</td>\n",
       "      <td>0.415360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.730801</td>\n",
       "      <td>0.736787</td>\n",
       "      <td>0.730044</td>\n",
       "      <td>0.751437</td>\n",
       "      <td>0.738497</td>\n",
       "      <td>0.742446</td>\n",
       "      <td>0.754657</td>\n",
       "      <td>0.733474</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.483352</td>\n",
       "      <td>0.487274</td>\n",
       "      <td>0.469153</td>\n",
       "      <td>0.487648</td>\n",
       "      <td>0.464026</td>\n",
       "      <td>0.451152</td>\n",
       "      <td>0.458229</td>\n",
       "      <td>0.440782</td>\n",
       "      <td>0.426193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770227</td>\n",
       "      <td>0.773013</td>\n",
       "      <td>0.761431</td>\n",
       "      <td>0.763488</td>\n",
       "      <td>0.762473</td>\n",
       "      <td>0.744012</td>\n",
       "      <td>0.775486</td>\n",
       "      <td>0.760431</td>\n",
       "      <td>0.751988</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>0.478140</td>\n",
       "      <td>0.444033</td>\n",
       "      <td>0.442120</td>\n",
       "      <td>0.437473</td>\n",
       "      <td>0.428672</td>\n",
       "      <td>0.413238</td>\n",
       "      <td>0.417758</td>\n",
       "      <td>0.420388</td>\n",
       "      <td>0.413290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747858</td>\n",
       "      <td>0.730535</td>\n",
       "      <td>0.716969</td>\n",
       "      <td>0.739297</td>\n",
       "      <td>0.724827</td>\n",
       "      <td>0.720484</td>\n",
       "      <td>0.740626</td>\n",
       "      <td>0.740116</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>0.409367</td>\n",
       "      <td>0.394941</td>\n",
       "      <td>0.380236</td>\n",
       "      <td>0.375340</td>\n",
       "      <td>0.346122</td>\n",
       "      <td>0.354650</td>\n",
       "      <td>0.361170</td>\n",
       "      <td>0.342974</td>\n",
       "      <td>0.352137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670232</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.661587</td>\n",
       "      <td>0.658422</td>\n",
       "      <td>0.644254</td>\n",
       "      <td>0.646479</td>\n",
       "      <td>0.656779</td>\n",
       "      <td>0.646700</td>\n",
       "      <td>0.646733</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.486526</td>\n",
       "      <td>0.501372</td>\n",
       "      <td>0.500175</td>\n",
       "      <td>0.508139</td>\n",
       "      <td>0.489411</td>\n",
       "      <td>0.457311</td>\n",
       "      <td>0.462321</td>\n",
       "      <td>0.462927</td>\n",
       "      <td>0.442647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787532</td>\n",
       "      <td>0.780347</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.771411</td>\n",
       "      <td>0.770919</td>\n",
       "      <td>0.761464</td>\n",
       "      <td>0.770314</td>\n",
       "      <td>0.763324</td>\n",
       "      <td>0.797187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>0.464595</td>\n",
       "      <td>0.498822</td>\n",
       "      <td>0.489077</td>\n",
       "      <td>0.453381</td>\n",
       "      <td>0.487636</td>\n",
       "      <td>0.461950</td>\n",
       "      <td>0.461671</td>\n",
       "      <td>0.447362</td>\n",
       "      <td>0.451952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739432</td>\n",
       "      <td>0.759722</td>\n",
       "      <td>0.752118</td>\n",
       "      <td>0.761910</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.730431</td>\n",
       "      <td>0.753545</td>\n",
       "      <td>0.749619</td>\n",
       "      <td>0.756383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0.460840</td>\n",
       "      <td>0.457656</td>\n",
       "      <td>0.434632</td>\n",
       "      <td>0.412675</td>\n",
       "      <td>0.418638</td>\n",
       "      <td>0.408338</td>\n",
       "      <td>0.403807</td>\n",
       "      <td>0.388811</td>\n",
       "      <td>0.382484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717509</td>\n",
       "      <td>0.726149</td>\n",
       "      <td>0.728631</td>\n",
       "      <td>0.725808</td>\n",
       "      <td>0.716943</td>\n",
       "      <td>0.718320</td>\n",
       "      <td>0.707611</td>\n",
       "      <td>0.729484</td>\n",
       "      <td>0.718706</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hsi_id         0         1         2         3         4         5  \\\n",
       "0         0  0.416181  0.396844  0.408985  0.372865  0.385293  0.365390   \n",
       "1         1  0.415797  0.402956  0.402564  0.396014  0.397192  0.389634   \n",
       "2         2  0.389023  0.371206  0.373098  0.373872  0.361056  0.349709   \n",
       "3         3  0.468837  0.473255  0.462949  0.459335  0.461672  0.459824   \n",
       "4         4  0.483352  0.487274  0.469153  0.487648  0.464026  0.451152   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "495     495  0.478140  0.444033  0.442120  0.437473  0.428672  0.413238   \n",
       "496     496  0.409367  0.394941  0.380236  0.375340  0.346122  0.354650   \n",
       "497     497  0.486526  0.501372  0.500175  0.508139  0.489411  0.457311   \n",
       "498     498  0.464595  0.498822  0.489077  0.453381  0.487636  0.461950   \n",
       "499     499  0.460840  0.457656  0.434632  0.412675  0.418638  0.408338   \n",
       "\n",
       "            6         7         8  ...       439       440       441  \\\n",
       "0    0.355226  0.343350  0.344837  ...  0.710280  0.717482  0.715078   \n",
       "1    0.375671  0.363689  0.373883  ...  0.684011  0.697271  0.701995   \n",
       "2    0.333882  0.330841  0.328925  ...  0.683054  0.669286  0.663179   \n",
       "3    0.458194  0.427737  0.415360  ...  0.742782  0.730801  0.736787   \n",
       "4    0.458229  0.440782  0.426193  ...  0.770227  0.773013  0.761431   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "495  0.417758  0.420388  0.413290  ...  0.747858  0.730535  0.716969   \n",
       "496  0.361170  0.342974  0.352137  ...  0.670232  0.659045  0.661587   \n",
       "497  0.462321  0.462927  0.442647  ...  0.787532  0.780347  0.768362   \n",
       "498  0.461671  0.447362  0.451952  ...  0.739432  0.759722  0.752118   \n",
       "499  0.403807  0.388811  0.382484  ...  0.717509  0.726149  0.728631   \n",
       "\n",
       "          442       443       444       445       446       447  vomitoxin_ppb  \n",
       "0    0.705379  0.696691  0.692793  0.711369  0.697679  0.704520         1100.0  \n",
       "1    0.696077  0.701012  0.677418  0.696921  0.696544  0.689054         1000.0  \n",
       "2    0.676165  0.676591  0.655951  0.658945  0.670989  0.665176         1300.0  \n",
       "3    0.730044  0.751437  0.738497  0.742446  0.754657  0.733474         1300.0  \n",
       "4    0.763488  0.762473  0.744012  0.775486  0.760431  0.751988          220.0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "495  0.739297  0.724827  0.720484  0.740626  0.740116  0.721839         1200.0  \n",
       "496  0.658422  0.644254  0.646479  0.656779  0.646700  0.646733            0.0  \n",
       "497  0.771411  0.770919  0.761464  0.770314  0.763324  0.797187            0.0  \n",
       "498  0.761910  0.761111  0.730431  0.753545  0.749619  0.756383            0.0  \n",
       "499  0.725808  0.716943  0.718320  0.707611  0.729484  0.718706         1400.0  \n",
       "\n",
       "[500 rows x 450 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA().fit(X_scaled)\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)  # Cumulative variance\n",
    "\n",
    "# Find the number of components that explain ~95% variance\n",
    "n_components = np.argmax(explained_variance >= 0.95) + 1\n",
    "print(f\"Optimal number of components: {n_components}\")\n",
    "\n",
    "# Step 2: Scree Plot (Elbow Method)\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label=\"95% Variance\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Reduce dimensions to 32 using PCA\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Apply t-SNE (max 2 or 3 components for visualization)\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_pca)\n",
    "\n",
    "# Visualize the t-SNE output\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], alpha=0.7)\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.title(\"t-SNE Visualization of Hyperspectral Data (After PCA)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (400, 4), Testing Set: (100, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `X_pca` is the PCA-reduced dataset and `y` is the target (DON concentration)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Set: {X_train.shape}, Testing Set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "MAE: 1900.474, RMSE: 4003.175, RÂ²: 0.943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Random Forest Results:\\nMAE: {mae:.3f}, RMSE: {rmse:.3f}, RÂ²: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 3s 12ms/step - loss: 153718624.0000 - mae: 3157.6392 - val_loss: 298978720.0000 - val_mae: 4409.8955\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 153692976.0000 - mae: 3155.0771 - val_loss: 298933504.0000 - val_mae: 4406.7861\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 153648416.0000 - mae: 3150.9431 - val_loss: 298849344.0000 - val_mae: 4401.6992\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 153578544.0000 - mae: 3144.8601 - val_loss: 298728928.0000 - val_mae: 4393.9629\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 153473328.0000 - mae: 3135.4319 - val_loss: 298529056.0000 - val_mae: 4382.6436\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 153308688.0000 - mae: 3123.6306 - val_loss: 298223328.0000 - val_mae: 4367.9937\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 153080976.0000 - mae: 3110.5781 - val_loss: 297860992.0000 - val_mae: 4351.7754\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 152800560.0000 - mae: 3096.8496 - val_loss: 297294080.0000 - val_mae: 4332.4639\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 152415344.0000 - mae: 3080.1665 - val_loss: 296555520.0000 - val_mae: 4312.4458\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 151920960.0000 - mae: 3064.7129 - val_loss: 295591744.0000 - val_mae: 4292.4067\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 151315648.0000 - mae: 3049.8625 - val_loss: 294442944.0000 - val_mae: 4276.7036\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 150597504.0000 - mae: 3038.5032 - val_loss: 292995648.0000 - val_mae: 4261.1401\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 149746880.0000 - mae: 3030.8848 - val_loss: 291384704.0000 - val_mae: 4250.1592\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 148879088.0000 - mae: 3025.6370 - val_loss: 289460640.0000 - val_mae: 4240.5713\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 147766448.0000 - mae: 3024.4878 - val_loss: 287804032.0000 - val_mae: 4241.1045\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 146755488.0000 - mae: 3026.5320 - val_loss: 285374432.0000 - val_mae: 4239.6870\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 145462112.0000 - mae: 3031.3875 - val_loss: 283031776.0000 - val_mae: 4244.4648\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 144311856.0000 - mae: 3046.0647 - val_loss: 279974048.0000 - val_mae: 4255.5347\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 142805952.0000 - mae: 3053.1443 - val_loss: 277198720.0000 - val_mae: 4263.3467\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 141409216.0000 - mae: 3057.8000 - val_loss: 273962944.0000 - val_mae: 4280.8374\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 139769904.0000 - mae: 3077.1931 - val_loss: 270779776.0000 - val_mae: 4304.2676\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 138151840.0000 - mae: 3092.9673 - val_loss: 267288128.0000 - val_mae: 4329.8564\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 136334784.0000 - mae: 3100.5259 - val_loss: 264008560.0000 - val_mae: 4348.0479\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 134798384.0000 - mae: 3119.9646 - val_loss: 259363280.0000 - val_mae: 4380.7202\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 132725568.0000 - mae: 3145.2400 - val_loss: 255406736.0000 - val_mae: 4404.1270\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 130884360.0000 - mae: 3155.0149 - val_loss: 251186384.0000 - val_mae: 4428.8882\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 128910776.0000 - mae: 3177.7747 - val_loss: 247189696.0000 - val_mae: 4453.9326\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 127001576.0000 - mae: 3189.0901 - val_loss: 243299040.0000 - val_mae: 4473.1821\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 125283504.0000 - mae: 3217.0483 - val_loss: 238015936.0000 - val_mae: 4500.7012\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 123145504.0000 - mae: 3235.9553 - val_loss: 233503536.0000 - val_mae: 4519.1177\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 121308904.0000 - mae: 3242.5510 - val_loss: 230166768.0000 - val_mae: 4526.3701\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 119372040.0000 - mae: 3259.5762 - val_loss: 225864832.0000 - val_mae: 4539.4243\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 117646312.0000 - mae: 3283.8972 - val_loss: 220874624.0000 - val_mae: 4557.4941\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 115683624.0000 - mae: 3305.6931 - val_loss: 217436352.0000 - val_mae: 4560.2222\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 114076824.0000 - mae: 3313.8987 - val_loss: 213754880.0000 - val_mae: 4562.2466\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 112513328.0000 - mae: 3331.7253 - val_loss: 209967248.0000 - val_mae: 4563.0220\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 111045200.0000 - mae: 3352.4006 - val_loss: 204955568.0000 - val_mae: 4576.8252\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 109461512.0000 - mae: 3377.5046 - val_loss: 201025840.0000 - val_mae: 4581.7847\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 107923360.0000 - mae: 3372.2488 - val_loss: 198313520.0000 - val_mae: 4567.7251\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 107133176.0000 - mae: 3408.3252 - val_loss: 193979808.0000 - val_mae: 4574.0088\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 105207744.0000 - mae: 3407.2344 - val_loss: 191262560.0000 - val_mae: 4568.2642\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 104222752.0000 - mae: 3415.1240 - val_loss: 188180128.0000 - val_mae: 4565.8643\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 102742160.0000 - mae: 3413.5491 - val_loss: 185921664.0000 - val_mae: 4558.8823\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 101737944.0000 - mae: 3391.0125 - val_loss: 184622144.0000 - val_mae: 4530.8745\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 100688208.0000 - mae: 3399.1555 - val_loss: 180855904.0000 - val_mae: 4541.3311\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 99546592.0000 - mae: 3402.0950 - val_loss: 178535872.0000 - val_mae: 4530.8203\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 98554808.0000 - mae: 3405.5007 - val_loss: 175755488.0000 - val_mae: 4527.6680\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 97759088.0000 - mae: 3412.7891 - val_loss: 173135648.0000 - val_mae: 4521.1235\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 96825376.0000 - mae: 3401.9546 - val_loss: 171389504.0000 - val_mae: 4502.5688\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 95939184.0000 - mae: 3407.5769 - val_loss: 169136320.0000 - val_mae: 4495.8687\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 94981056.0000 - mae: 3393.8528 - val_loss: 167734720.0000 - val_mae: 4471.1958\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 94422888.0000 - mae: 3398.3445 - val_loss: 165214112.0000 - val_mae: 4471.9170\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 93508896.0000 - mae: 3396.7253 - val_loss: 163664192.0000 - val_mae: 4457.9033\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 92791744.0000 - mae: 3369.7834 - val_loss: 163123856.0000 - val_mae: 4427.6772\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 92279440.0000 - mae: 3381.1294 - val_loss: 160127072.0000 - val_mae: 4438.4863\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 91393800.0000 - mae: 3370.0569 - val_loss: 158760768.0000 - val_mae: 4422.2773\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 90811368.0000 - mae: 3363.4275 - val_loss: 157324592.0000 - val_mae: 4410.7305\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 90137672.0000 - mae: 3362.2646 - val_loss: 155813424.0000 - val_mae: 4402.9951\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 89673288.0000 - mae: 3354.7871 - val_loss: 154054400.0000 - val_mae: 4396.6523\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 89133464.0000 - mae: 3366.9312 - val_loss: 152342400.0000 - val_mae: 4397.9248\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 88658864.0000 - mae: 3347.9915 - val_loss: 151535296.0000 - val_mae: 4379.4512\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 88507728.0000 - mae: 3329.4546 - val_loss: 151308880.0000 - val_mae: 4354.7495\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 87782064.0000 - mae: 3338.5393 - val_loss: 149124096.0000 - val_mae: 4360.7153\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 87249408.0000 - mae: 3338.7000 - val_loss: 148132000.0000 - val_mae: 4349.7339\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 86960336.0000 - mae: 3340.5791 - val_loss: 146680128.0000 - val_mae: 4344.6108\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 86907232.0000 - mae: 3323.5432 - val_loss: 145869664.0000 - val_mae: 4330.1152\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 86036296.0000 - mae: 3322.9612 - val_loss: 144974320.0000 - val_mae: 4323.2603\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 85769840.0000 - mae: 3329.8638 - val_loss: 143496832.0000 - val_mae: 4322.4170\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 85362864.0000 - mae: 3317.9170 - val_loss: 142953248.0000 - val_mae: 4305.5293\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 85115568.0000 - mae: 3319.3313 - val_loss: 141809632.0000 - val_mae: 4300.6235\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 85046680.0000 - mae: 3300.6250 - val_loss: 142221712.0000 - val_mae: 4274.8496\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 84817584.0000 - mae: 3312.6394 - val_loss: 140070064.0000 - val_mae: 4285.9316\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 84228168.0000 - mae: 3308.5667 - val_loss: 139133408.0000 - val_mae: 4281.1255\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 84012744.0000 - mae: 3293.1819 - val_loss: 139261104.0000 - val_mae: 4259.8320\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 83838160.0000 - mae: 3293.6418 - val_loss: 138352240.0000 - val_mae: 4253.9766\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 83551312.0000 - mae: 3285.6543 - val_loss: 137146608.0000 - val_mae: 4256.3042\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 83325888.0000 - mae: 3293.3215 - val_loss: 136315632.0000 - val_mae: 4251.3662\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 83019592.0000 - mae: 3280.4863 - val_loss: 136305904.0000 - val_mae: 4234.0239\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 83105872.0000 - mae: 3286.1956 - val_loss: 134976640.0000 - val_mae: 4236.9048\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 82682136.0000 - mae: 3275.5913 - val_loss: 134964512.0000 - val_mae: 4220.2573\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 82764800.0000 - mae: 3283.9673 - val_loss: 133423768.0000 - val_mae: 4227.9985\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 82274600.0000 - mae: 3267.8613 - val_loss: 134031912.0000 - val_mae: 4206.6255\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 82311680.0000 - mae: 3255.0867 - val_loss: 132983592.0000 - val_mae: 4205.5645\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 82015784.0000 - mae: 3258.8154 - val_loss: 132141288.0000 - val_mae: 4201.8608\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 81804320.0000 - mae: 3255.4341 - val_loss: 131757264.0000 - val_mae: 4195.7285\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 81623672.0000 - mae: 3249.4231 - val_loss: 131240880.0000 - val_mae: 4188.9375\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 81506920.0000 - mae: 3243.0149 - val_loss: 130721024.0000 - val_mae: 4179.9546\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 81441360.0000 - mae: 3236.5256 - val_loss: 130272464.0000 - val_mae: 4174.6802\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 81267544.0000 - mae: 3238.1284 - val_loss: 129676328.0000 - val_mae: 4171.4336\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 81377320.0000 - mae: 3240.7664 - val_loss: 128708744.0000 - val_mae: 4170.8452\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 81228296.0000 - mae: 3231.5701 - val_loss: 129032848.0000 - val_mae: 4157.5991\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 80993328.0000 - mae: 3215.8369 - val_loss: 129288656.0000 - val_mae: 4141.5845\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 80743272.0000 - mae: 3215.1541 - val_loss: 128083320.0000 - val_mae: 4145.2505\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 80610328.0000 - mae: 3210.3792 - val_loss: 128054520.0000 - val_mae: 4133.1221\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 80489784.0000 - mae: 3214.3491 - val_loss: 127272448.0000 - val_mae: 4132.9580\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 80399776.0000 - mae: 3207.6306 - val_loss: 126964800.0000 - val_mae: 4126.5688\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 80478496.0000 - mae: 3194.2061 - val_loss: 127117200.0000 - val_mae: 4111.5029\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 80133576.0000 - mae: 3192.9006 - val_loss: 126622144.0000 - val_mae: 4111.2163\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 80093304.0000 - mae: 3191.4746 - val_loss: 126247072.0000 - val_mae: 4105.3394\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 80067888.0000 - mae: 3197.0874 - val_loss: 125755784.0000 - val_mae: 4102.0020\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Neural Network Results:\n",
      "MAE: 4102.002, RMSE: 11214.089, RÂ²: 0.550\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Build Neural Network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer (1 neuron for regression)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred_nn = model.predict(X_test).flatten()\n",
    "\n",
    "# Calculate Metrics\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test, y_pred_nn))\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "print(f\"Neural Network Results:\\nMAE: {mae_nn:.3f}, RMSE: {rmse_nn:.3f}, RÂ²: {r2_nn:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (400, 4, 1), Test Shape: (100, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reshape data: Convert (samples, features) â†’ (samples, timesteps, features)\n",
    "n_timesteps = X_pca.shape[1]  \n",
    "X_lstm = X_pca.reshape((X_pca.shape[0], n_timesteps, 1))  # Reshaping for LSTM\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}, Test Shape: {X_test.shape}\")  # Should be (samples, timesteps, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuning_results\\lstm_hyperopt\\tuner0.json\n",
      "Best Hyperparameters: {'lstm_units_1': 128, 'dropout_1': 0.3, 'lstm_units_2': 64, 'dropout_2': 0.2, 'dense_units': 128, 'dropout_3': 0.4, 'lr': 0.001}\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 6s 97ms/step - loss: 153712080.0000 - mae: 3157.8909 - val_loss: 299002272.0000 - val_mae: 4412.6758\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 153693536.0000 - mae: 3156.4893 - val_loss: 298996096.0000 - val_mae: 4412.3457\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 153664304.0000 - mae: 3155.3843 - val_loss: 298985856.0000 - val_mae: 4411.9043\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 153623408.0000 - mae: 3154.0959 - val_loss: 298968256.0000 - val_mae: 4411.3354\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 153563968.0000 - mae: 3152.6169 - val_loss: 298949312.0000 - val_mae: 4410.8442\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 153503696.0000 - mae: 3151.5100 - val_loss: 298918880.0000 - val_mae: 4410.3164\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 153317920.0000 - mae: 3149.0823 - val_loss: 298902720.0000 - val_mae: 4410.5518\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 153169328.0000 - mae: 3147.3027 - val_loss: 298735232.0000 - val_mae: 4408.2305\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 153112640.0000 - mae: 3145.7722 - val_loss: 298707232.0000 - val_mae: 4408.1792\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 152913600.0000 - mae: 3141.2188 - val_loss: 298575008.0000 - val_mae: 4406.6621\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 152814320.0000 - mae: 3138.3384 - val_loss: 298278432.0000 - val_mae: 4402.2407\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 152592256.0000 - mae: 3135.8440 - val_loss: 298057536.0000 - val_mae: 4397.9600\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 152295632.0000 - mae: 3130.5840 - val_loss: 297981184.0000 - val_mae: 4398.9312\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 151907680.0000 - mae: 3126.5393 - val_loss: 297635136.0000 - val_mae: 4394.0488\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 151527488.0000 - mae: 3124.3054 - val_loss: 297171136.0000 - val_mae: 4392.1797\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 150906672.0000 - mae: 3117.8110 - val_loss: 297158688.0000 - val_mae: 4391.1670\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 151178496.0000 - mae: 3112.6240 - val_loss: 296339040.0000 - val_mae: 4381.0894\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 150269872.0000 - mae: 3101.4517 - val_loss: 295340864.0000 - val_mae: 4373.7422\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 150054944.0000 - mae: 3095.3796 - val_loss: 295682464.0000 - val_mae: 4377.6533\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 149927312.0000 - mae: 3091.4680 - val_loss: 293849728.0000 - val_mae: 4359.0977\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 149319600.0000 - mae: 3085.9658 - val_loss: 292404768.0000 - val_mae: 4338.3262\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 148141920.0000 - mae: 3069.9004 - val_loss: 291783456.0000 - val_mae: 4340.5352\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 148070720.0000 - mae: 3042.3196 - val_loss: 290764512.0000 - val_mae: 4334.0645\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 148011264.0000 - mae: 3049.2510 - val_loss: 288867904.0000 - val_mae: 4315.0059\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 147480160.0000 - mae: 3040.2424 - val_loss: 287598048.0000 - val_mae: 4298.0684\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 145923760.0000 - mae: 3021.6963 - val_loss: 286269824.0000 - val_mae: 4284.7959\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 144441408.0000 - mae: 3017.5437 - val_loss: 285317568.0000 - val_mae: 4280.4829\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 145712624.0000 - mae: 3016.8057 - val_loss: 281670400.0000 - val_mae: 4237.6309\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 143585952.0000 - mae: 3011.0818 - val_loss: 280018112.0000 - val_mae: 4228.5454\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 143543888.0000 - mae: 2968.9338 - val_loss: 279753344.0000 - val_mae: 4231.0254\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 144310816.0000 - mae: 2993.2068 - val_loss: 276576832.0000 - val_mae: 4205.5605\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 142363744.0000 - mae: 2946.2234 - val_loss: 273860576.0000 - val_mae: 4179.0498\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 140146656.0000 - mae: 2956.6685 - val_loss: 270833088.0000 - val_mae: 4143.1812\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 140088592.0000 - mae: 2969.2671 - val_loss: 269062816.0000 - val_mae: 4141.0483\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 139960368.0000 - mae: 2932.7393 - val_loss: 269181280.0000 - val_mae: 4146.0781\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 137712320.0000 - mae: 2916.6716 - val_loss: 262724656.0000 - val_mae: 4045.0840\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 139181728.0000 - mae: 2922.9009 - val_loss: 261306144.0000 - val_mae: 4090.5605\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 136184624.0000 - mae: 2892.7429 - val_loss: 271378272.0000 - val_mae: 4137.0664\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 141313904.0000 - mae: 2949.6123 - val_loss: 255920400.0000 - val_mae: 4042.8623\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 132177808.0000 - mae: 2899.8828 - val_loss: 253149904.0000 - val_mae: 4034.6577\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 135481216.0000 - mae: 2906.8472 - val_loss: 250069952.0000 - val_mae: 4012.7905\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 134727120.0000 - mae: 2857.4153 - val_loss: 247769648.0000 - val_mae: 3971.2642\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 132501152.0000 - mae: 2864.8782 - val_loss: 245915664.0000 - val_mae: 3990.0654\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 133721968.0000 - mae: 2896.8162 - val_loss: 246341488.0000 - val_mae: 3984.4685\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 128057200.0000 - mae: 2812.9419 - val_loss: 239961728.0000 - val_mae: 3962.9712\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 129525832.0000 - mae: 2866.6865 - val_loss: 235749056.0000 - val_mae: 3949.7446\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 132457936.0000 - mae: 2860.6860 - val_loss: 233350080.0000 - val_mae: 3932.6282\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 129203208.0000 - mae: 2774.2324 - val_loss: 230702640.0000 - val_mae: 3921.9175\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 126630000.0000 - mae: 2882.4060 - val_loss: 228504656.0000 - val_mae: 3937.2607\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 122710640.0000 - mae: 2863.4026 - val_loss: 225780944.0000 - val_mae: 3922.5906\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 126984776.0000 - mae: 2910.9299 - val_loss: 220833792.0000 - val_mae: 3905.3652\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 119320568.0000 - mae: 2734.9795 - val_loss: 216981888.0000 - val_mae: 3880.0186\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 120499968.0000 - mae: 2775.6626 - val_loss: 213848416.0000 - val_mae: 3850.3091\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 121540616.0000 - mae: 2786.1204 - val_loss: 210693792.0000 - val_mae: 3845.1343\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 116116960.0000 - mae: 2810.2759 - val_loss: 208162032.0000 - val_mae: 3881.0979\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 113672056.0000 - mae: 2837.4795 - val_loss: 203939744.0000 - val_mae: 3854.6816\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 120065248.0000 - mae: 2948.1240 - val_loss: 200978368.0000 - val_mae: 3818.8630\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 113217544.0000 - mae: 2869.8296 - val_loss: 197757648.0000 - val_mae: 3829.6147\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 111349880.0000 - mae: 2839.1462 - val_loss: 194925712.0000 - val_mae: 3844.9272\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 111341448.0000 - mae: 2930.3486 - val_loss: 187587488.0000 - val_mae: 3817.5930\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 112482680.0000 - mae: 2862.8557 - val_loss: 183363568.0000 - val_mae: 3794.8452\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 101893704.0000 - mae: 2762.4070 - val_loss: 178114864.0000 - val_mae: 3788.1655\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 102011800.0000 - mae: 2810.3057 - val_loss: 174280768.0000 - val_mae: 3774.0806\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 107755784.0000 - mae: 2899.0701 - val_loss: 170042560.0000 - val_mae: 3743.4338\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 105410040.0000 - mae: 2889.8936 - val_loss: 168450112.0000 - val_mae: 3765.4385\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 100093112.0000 - mae: 2874.8931 - val_loss: 162833856.0000 - val_mae: 3747.1118\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 102791984.0000 - mae: 2950.5801 - val_loss: 160831136.0000 - val_mae: 3692.3425\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 99614984.0000 - mae: 2944.1135 - val_loss: 170725904.0000 - val_mae: 3894.0867\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 97605280.0000 - mae: 2933.4075 - val_loss: 152330480.0000 - val_mae: 3771.6108\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 104569792.0000 - mae: 2960.7085 - val_loss: 156500304.0000 - val_mae: 3944.2188\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 97750296.0000 - mae: 2986.0662 - val_loss: 150443136.0000 - val_mae: 3783.6506\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 98241056.0000 - mae: 3020.2593 - val_loss: 149077952.0000 - val_mae: 3766.7881\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 96003024.0000 - mae: 2960.7700 - val_loss: 156633808.0000 - val_mae: 3820.7581\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 96958240.0000 - mae: 3103.6799 - val_loss: 164729184.0000 - val_mae: 3896.3484\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 94585832.0000 - mae: 3001.8503 - val_loss: 138985024.0000 - val_mae: 3659.8564\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 91262976.0000 - mae: 2904.9377 - val_loss: 132974456.0000 - val_mae: 3642.7842\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 97665216.0000 - mae: 3129.5449 - val_loss: 130320336.0000 - val_mae: 3666.8647\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 93955392.0000 - mae: 3032.9424 - val_loss: 126590256.0000 - val_mae: 3671.5046\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 82899168.0000 - mae: 2910.9021 - val_loss: 124117288.0000 - val_mae: 3651.7354\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 91354120.0000 - mae: 2989.1353 - val_loss: 122652864.0000 - val_mae: 3610.6494\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 89182760.0000 - mae: 3178.4241 - val_loss: 125414792.0000 - val_mae: 3632.8425\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 84193856.0000 - mae: 2977.0996 - val_loss: 125299008.0000 - val_mae: 3682.3293\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 86832152.0000 - mae: 3236.8918 - val_loss: 108541432.0000 - val_mae: 3600.9297\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 82161952.0000 - mae: 3042.1130 - val_loss: 107952480.0000 - val_mae: 3578.8357\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 86026528.0000 - mae: 3114.0068 - val_loss: 102482736.0000 - val_mae: 3569.9382\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 81151280.0000 - mae: 3292.2532 - val_loss: 96188320.0000 - val_mae: 3500.1509\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 74693920.0000 - mae: 3009.9951 - val_loss: 90992464.0000 - val_mae: 3381.4438\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 80982896.0000 - mae: 2969.4561 - val_loss: 89060712.0000 - val_mae: 3368.9229\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 82443328.0000 - mae: 2977.7976 - val_loss: 103060760.0000 - val_mae: 3472.4148\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 78572088.0000 - mae: 3020.4333 - val_loss: 74008848.0000 - val_mae: 3310.8262\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 73136232.0000 - mae: 3049.4268 - val_loss: 73217872.0000 - val_mae: 3276.1877\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 71235992.0000 - mae: 2877.8467 - val_loss: 71764752.0000 - val_mae: 3230.3237\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 78900032.0000 - mae: 2938.1128 - val_loss: 72053608.0000 - val_mae: 3234.4578\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 63718728.0000 - mae: 2761.6409 - val_loss: 72565128.0000 - val_mae: 3223.1316\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 78943008.0000 - mae: 3028.6118 - val_loss: 65823044.0000 - val_mae: 3150.2866\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 74033264.0000 - mae: 3014.8757 - val_loss: 63327840.0000 - val_mae: 3131.2397\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 73603920.0000 - mae: 2854.5493 - val_loss: 61805196.0000 - val_mae: 3117.5767\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 72614376.0000 - mae: 2798.3760 - val_loss: 75503288.0000 - val_mae: 3220.8367\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 61282912.0000 - mae: 2758.6318 - val_loss: 50102728.0000 - val_mae: 2979.4668\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 72872096.0000 - mae: 2967.4575 - val_loss: 49488144.0000 - val_mae: 2974.7920\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "Optimized LSTM Performance:\n",
      "MAE: 2974.792, RMSE: 7034.781, RÂ²: 0.823\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Define the hypermodel function\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        LSTM(units=hp.Choice('lstm_units_1', [32, 64, 128]), \n",
    "             return_sequences=True, \n",
    "             input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        BatchNormalization(),\n",
    "        Dropout(hp.Choice('dropout_1', [0.2, 0.3, 0.4])),\n",
    "\n",
    "        LSTM(units=hp.Choice('lstm_units_2', [32, 64, 128]), return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(hp.Choice('dropout_2', [0.2, 0.3, 0.4])),\n",
    "\n",
    "        Dense(hp.Choice('dense_units', [32, 64, 128]), activation='relu'),\n",
    "        Dropout(hp.Choice('dropout_3', [0.2, 0.3, 0.4])),\n",
    "\n",
    "        Dense(1)  # Regression output\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('lr', [0.001, 0.0005, 0.0001])),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuning_results',\n",
    "    project_name='lstm_hyperopt'\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")\n",
    "\n",
    "# Train the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred_best = best_model.predict(X_test).flatten()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_best)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2 = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Optimized LSTM Performance:\\nMAE: {mae:.3f}, RMSE: {rmse:.3f}, RÂ²: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (400, 4, 1), Test Shape: (100, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reshape data for CNN\n",
    "X_cnn = X_pca.reshape((X_pca.shape[0], X_pca.shape[1], 1))  # Shape: (samples, timesteps, channels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cnn, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}, Test Shape: {X_test.shape}\")  # Should be (samples, timesteps, channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 26ms/step - loss: 153707600.0000 - mae: 3157.2869 - val_loss: 298961984.0000 - val_mae: 4411.1768\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 153557904.0000 - mae: 3150.7197 - val_loss: 298871360.0000 - val_mae: 4408.0034\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 153282400.0000 - mae: 3138.3452 - val_loss: 298551968.0000 - val_mae: 4400.6494\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 152682528.0000 - mae: 3112.8564 - val_loss: 297715968.0000 - val_mae: 4384.4951\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 150887808.0000 - mae: 3064.0825 - val_loss: 295927520.0000 - val_mae: 4349.1890\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 148226864.0000 - mae: 2988.0410 - val_loss: 292527968.0000 - val_mae: 4286.5698\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 144663184.0000 - mae: 2924.9465 - val_loss: 286500608.0000 - val_mae: 4204.0103\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 138603936.0000 - mae: 2850.6353 - val_loss: 276475616.0000 - val_mae: 4082.8430\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 130253488.0000 - mae: 2801.2207 - val_loss: 265554016.0000 - val_mae: 3990.1460\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 124130048.0000 - mae: 2779.9229 - val_loss: 250652320.0000 - val_mae: 3903.1812\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 115094368.0000 - mae: 2773.0076 - val_loss: 230328688.0000 - val_mae: 3823.2351\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 108706336.0000 - mae: 2803.7810 - val_loss: 219829088.0000 - val_mae: 3754.5071\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 99504152.0000 - mae: 2668.0127 - val_loss: 197029824.0000 - val_mae: 3673.6909\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 103252672.0000 - mae: 2782.9155 - val_loss: 190865984.0000 - val_mae: 3595.2451\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 86378280.0000 - mae: 2608.2095 - val_loss: 173842480.0000 - val_mae: 3527.0247\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 88049664.0000 - mae: 2731.8005 - val_loss: 161602512.0000 - val_mae: 3476.8740\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 81358824.0000 - mae: 2657.0603 - val_loss: 151236752.0000 - val_mae: 3360.0918\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 81574760.0000 - mae: 2621.7312 - val_loss: 150018112.0000 - val_mae: 3307.3013\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 76361336.0000 - mae: 2569.8010 - val_loss: 132040480.0000 - val_mae: 3283.8394\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 77747472.0000 - mae: 2517.1821 - val_loss: 123953248.0000 - val_mae: 3225.6343\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 68997912.0000 - mae: 2422.8635 - val_loss: 112504792.0000 - val_mae: 3233.1873\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 74396608.0000 - mae: 2659.7725 - val_loss: 106219000.0000 - val_mae: 3125.9800\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 61908112.0000 - mae: 2581.1624 - val_loss: 104874784.0000 - val_mae: 3043.4028\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 64310388.0000 - mae: 2444.9221 - val_loss: 106375048.0000 - val_mae: 3062.4065\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 72223256.0000 - mae: 2425.9719 - val_loss: 100570336.0000 - val_mae: 3066.8887\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 72509232.0000 - mae: 2719.3369 - val_loss: 80606640.0000 - val_mae: 3014.5945\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 63827256.0000 - mae: 2459.2039 - val_loss: 89286936.0000 - val_mae: 2966.6228\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 63959860.0000 - mae: 2426.6963 - val_loss: 87248272.0000 - val_mae: 2991.9663\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 63134384.0000 - mae: 2466.5220 - val_loss: 82065072.0000 - val_mae: 2959.6843\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 65267912.0000 - mae: 2661.0796 - val_loss: 68961200.0000 - val_mae: 2816.3296\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 59699160.0000 - mae: 2521.7400 - val_loss: 87896680.0000 - val_mae: 2879.7798\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 60011588.0000 - mae: 2379.8252 - val_loss: 62623160.0000 - val_mae: 2815.5769\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 60741168.0000 - mae: 2390.4500 - val_loss: 68650776.0000 - val_mae: 2858.8135\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 50807356.0000 - mae: 2343.3208 - val_loss: 64399104.0000 - val_mae: 2801.3188\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 61549644.0000 - mae: 2392.6865 - val_loss: 64451664.0000 - val_mae: 2756.3550\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 49214132.0000 - mae: 2433.3538 - val_loss: 59642896.0000 - val_mae: 2658.5515\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 46291840.0000 - mae: 2211.2678 - val_loss: 55136712.0000 - val_mae: 2628.4858\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 50638132.0000 - mae: 2385.2859 - val_loss: 50600040.0000 - val_mae: 2653.3213\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51407556.0000 - mae: 2446.6179 - val_loss: 61773000.0000 - val_mae: 2708.6982\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 40855684.0000 - mae: 2112.2559 - val_loss: 43166468.0000 - val_mae: 2435.5415\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 40911884.0000 - mae: 2101.8625 - val_loss: 48821748.0000 - val_mae: 2564.3650\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 49937028.0000 - mae: 2343.0554 - val_loss: 40894524.0000 - val_mae: 2465.9287\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 42451396.0000 - mae: 2181.3486 - val_loss: 36998992.0000 - val_mae: 2391.6313\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 48712264.0000 - mae: 2239.1191 - val_loss: 36928588.0000 - val_mae: 2390.7603\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 59673452.0000 - mae: 2409.3943 - val_loss: 35789712.0000 - val_mae: 2401.2681\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 39636668.0000 - mae: 2209.9946 - val_loss: 37970796.0000 - val_mae: 2398.8057\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 33686436.0000 - mae: 2065.4727 - val_loss: 29103600.0000 - val_mae: 2200.1294\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 40401484.0000 - mae: 2050.9934 - val_loss: 44629784.0000 - val_mae: 2432.0149\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 45277184.0000 - mae: 2179.6946 - val_loss: 28109320.0000 - val_mae: 2143.0654\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 69568224.0000 - mae: 2561.6592 - val_loss: 31174722.0000 - val_mae: 2216.8469\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 44087148.0000 - mae: 2238.0376 - val_loss: 29367400.0000 - val_mae: 2314.4216\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 42243232.0000 - mae: 2129.2307 - val_loss: 24461420.0000 - val_mae: 2039.1631\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 36985168.0000 - mae: 2260.4451 - val_loss: 23372826.0000 - val_mae: 2103.7837\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 32623306.0000 - mae: 2102.5967 - val_loss: 36348020.0000 - val_mae: 2327.0266\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 34700792.0000 - mae: 2127.9021 - val_loss: 25539348.0000 - val_mae: 2096.1211\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 35593024.0000 - mae: 2039.9031 - val_loss: 22085016.0000 - val_mae: 2003.0164\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 50721320.0000 - mae: 2327.4946 - val_loss: 58174076.0000 - val_mae: 2518.6687\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 49965884.0000 - mae: 2245.1626 - val_loss: 37037896.0000 - val_mae: 2491.9265\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 39530508.0000 - mae: 2221.7544 - val_loss: 25912510.0000 - val_mae: 2204.7212\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 31946406.0000 - mae: 1930.3862 - val_loss: 21730686.0000 - val_mae: 1980.9675\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 36018464.0000 - mae: 2185.9656 - val_loss: 18659364.0000 - val_mae: 1900.3367\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 43293104.0000 - mae: 2056.6995 - val_loss: 21213428.0000 - val_mae: 1979.5164\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 32624460.0000 - mae: 1902.1167 - val_loss: 31303012.0000 - val_mae: 2070.1096\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 21457650.0000 - mae: 1864.8389 - val_loss: 24181224.0000 - val_mae: 2105.5066\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 20839984.0000 - mae: 1879.1520 - val_loss: 25872966.0000 - val_mae: 2099.0186\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 30284528.0000 - mae: 2000.5938 - val_loss: 24717624.0000 - val_mae: 2088.4978\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 30560072.0000 - mae: 1917.6879 - val_loss: 21072450.0000 - val_mae: 1965.0590\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 32797002.0000 - mae: 2084.4180 - val_loss: 24229822.0000 - val_mae: 1996.6472\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 31874662.0000 - mae: 1917.6807 - val_loss: 36958324.0000 - val_mae: 2171.5220\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 32425534.0000 - mae: 1888.3250 - val_loss: 27674132.0000 - val_mae: 2051.1482\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 25014356.0000 - mae: 1934.9678 - val_loss: 32590248.0000 - val_mae: 2064.2002\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 18659364.0000 - mae: 1900.3367\n",
      "Test MAE: 1900.337\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the CNN Model\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='linear')  # Regression Output\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Assuming X_train.shape = (num_samples, num_wavelengths, 1)\n",
    "input_shape = (X_train.shape[1], 1)  \n",
    "model = build_cnn_model(input_shape)\n",
    "\n",
    "# Early Stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=200, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate Performance\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {test_mae:.3f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4319.646, RÂ² Score: 0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Root Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
    "\n",
    "print(f\"RMSE: {rmse:.3f}, RÂ² Score: {r2:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
